2025-05-30 17:11:27 - YouTubeScraper - INFO - üöÄ Starting website scraping tests
2025-05-30 17:11:27 - YouTubeScraper - INFO - ============================================================
2025-05-30 17:11:27 - YouTubeScraper - INFO - Testing Direct HTTP Scraping Method
2025-05-30 17:11:27 - YouTubeScraper - INFO - ============================================================
2025-05-30 17:11:27 - YouTubeScraper - INFO - üß™ Testing scraping with method: direct
2025-05-30 17:11:27 - YouTubeScraper - INFO - Initialized WebsitesScraping with 2 URLs
2025-05-30 17:11:27 - YouTubeScraper - INFO - Scraping method: direct
2025-05-30 17:11:27 - YouTubeScraper - INFO - URLs to process: ['paginasamarillas.com.do', 'www.hoteltoachi.com']
2025-05-30 17:11:27 - YouTubeScraper - INFO - üöÄ Starting complete scrape-and-extract pipeline
2025-05-30 17:11:27 - YouTubeScraper - INFO - üì° Phase 1: Website scraping
2025-05-30 17:11:27 - YouTubeScraper - INFO - üöÄ Starting website scraping using method: direct
2025-05-30 17:11:27 - YouTubeScraper - INFO - Starting direct HTTP scraping for 2 URLs
2025-05-30 17:11:27 - YouTubeScraper - DEBUG - Starting direct scraping for: paginasamarillas.com.do
2025-05-30 17:11:27 - YouTubeScraper - DEBUG - Starting direct scraping for: www.hoteltoachi.com
2025-05-30 17:11:28 - YouTubeScraper - INFO - ‚úÖ Successfully scraped 'www.hoteltoachi.com' - HTML length: 25,430
2025-05-30 17:11:29 - YouTubeScraper - INFO - ‚úÖ Successfully scraped 'paginasamarillas.com.do' - HTML length: 140,608
2025-05-30 17:11:30 - YouTubeScraper - INFO - Direct scraping completed - Success: 2/2
2025-05-30 17:11:30 - YouTubeScraper - INFO - ‚úÖ Scraping completed in 2.68 seconds
2025-05-30 17:11:30 - YouTubeScraper - INFO - üíæ Saved debug file for LLM to 'debug_files/website_scraping/temp_processed_data (2025-05-30_17-11-30).json'
2025-05-30 17:11:30 - YouTubeScraper - DEBUG - Debug files saved successfully
2025-05-30 17:11:30 - YouTubeScraper - INFO - Valid scraped data for LLM processing: 2/2
2025-05-30 17:11:30 - YouTubeScraper - INFO - ü§ñ Phase 2: LLM data extraction
2025-05-30 17:11:30 - YouTubeScraper - INFO - Initialized LLMDataExtractor with 2 input items
2025-05-30 17:11:30 - YouTubeScraper - INFO - Schema type: website
2025-05-30 17:11:30 - YouTubeScraper - INFO - Starting extraction of 2 items using method: crawl4ai
2025-05-30 17:11:30 - YouTubeScraper - INFO - Schema type: website
2025-05-30 17:11:30 - YouTubeScraper - INFO - Processing batch 1/1 with 2 items
2025-05-30 17:11:30 - YouTubeScraper - INFO - Starting Crawl4AI extraction for URL: 'https://paginasamarillas.com.do/en/business/search/republica-dominicana/c/directorios-telefonicos-y-guias'
2025-05-30 17:11:30 - YouTubeScraper - INFO - Starting Crawl4AI extraction for URL: 'http://www.hoteltoachi.com/'
2025-05-30 17:11:35 - YouTubeScraper - DEBUG - Processed array response by selecting first valid element
2025-05-30 17:11:35 - YouTubeScraper - INFO - ‚úÖ Successfully extracted and validated data via Crawl4AI for URL: http://www.hoteltoachi.com/
2025-05-30 17:17:34 - YouTubeScraper - ERROR - Error loading input file input/website_urls_list.json: Expecting value: line 1 column 1 (char 0)
2025-05-30 17:17:34 - YouTubeScraper - ERROR - No URLs provided for website scraping.
2025-05-30 17:20:35 - YouTubeScraper - INFO - Starting website scraping with method 'direct' for 2 URLs...
2025-05-30 17:20:36 - YouTubeScraper - INFO - Initialized WebsitesScraping with 2 URLs
2025-05-30 17:20:36 - YouTubeScraper - INFO - Scraping method: direct
2025-05-30 17:20:36 - YouTubeScraper - INFO - URLs to process: ['paginasamarillas.com.do', 'www.hoteltoachi.com']
2025-05-30 17:20:36 - YouTubeScraper - INFO - üöÄ Starting complete scrape-and-extract pipeline
2025-05-30 17:20:36 - YouTubeScraper - INFO - üì° Phase 1: Website scraping
2025-05-30 17:20:36 - YouTubeScraper - INFO - üöÄ Starting website scraping using method: direct
2025-05-30 17:20:36 - YouTubeScraper - INFO - Starting direct HTTP scraping for 2 URLs
2025-05-30 17:20:36 - YouTubeScraper - DEBUG - Starting direct scraping for: paginasamarillas.com.do
2025-05-30 17:20:36 - YouTubeScraper - DEBUG - Starting direct scraping for: www.hoteltoachi.com
2025-05-30 17:20:36 - YouTubeScraper - INFO - ‚úÖ Successfully scraped 'www.hoteltoachi.com' - HTML length: 25,430
2025-05-30 17:20:37 - YouTubeScraper - INFO - ‚úÖ Successfully scraped 'paginasamarillas.com.do' - HTML length: 128,989
2025-05-30 17:20:38 - YouTubeScraper - INFO - Direct scraping completed - Success: 2/2
2025-05-30 17:20:38 - YouTubeScraper - INFO - ‚úÖ Scraping completed in 2.83 seconds
2025-05-30 17:20:38 - YouTubeScraper - INFO - üíæ Saved debug file for LLM to 'debug_files/website_scraping/temp_processed_data (2025-05-30_17-20-38).json'
2025-05-30 17:20:38 - YouTubeScraper - DEBUG - Debug files saved successfully
2025-05-30 17:20:38 - YouTubeScraper - INFO - Valid scraped data for LLM processing: 2/2
2025-05-30 17:20:38 - YouTubeScraper - INFO - ü§ñ Phase 2: LLM data extraction
2025-05-30 17:20:39 - YouTubeScraper - INFO - Initialized LLMDataExtractor with 2 input items
2025-05-30 17:20:39 - YouTubeScraper - INFO - Schema type: website
2025-05-30 17:20:39 - YouTubeScraper - INFO - Starting extraction of 2 items using method: crawl4ai
2025-05-30 17:20:39 - YouTubeScraper - INFO - Schema type: website
2025-05-30 17:20:39 - YouTubeScraper - INFO - Processing batch 1/1 with 2 items
2025-05-30 17:20:39 - YouTubeScraper - INFO - Starting Crawl4AI extraction for URL: 'https://paginasamarillas.com.do/en/business/search/republica-dominicana/c/directorios-telef%C3%B3nicos-y-guias'
2025-05-30 17:20:39 - YouTubeScraper - INFO - Starting Crawl4AI extraction for URL: 'http://www.hoteltoachi.com/'
2025-05-30 17:20:45 - YouTubeScraper - DEBUG - Processed array response by selecting first valid element
2025-05-30 17:20:45 - YouTubeScraper - INFO - ‚úÖ Successfully extracted and validated data via Crawl4AI for URL: http://www.hoteltoachi.com/
2025-05-30 17:20:50 - YouTubeScraper - DEBUG - Processed array response by selecting first valid element
2025-05-30 17:20:50 - YouTubeScraper - INFO - ‚úÖ Successfully extracted and validated data via Crawl4AI for URL: https://paginasamarillas.com.do/en/business/search/republica-dominicana/c/directorios-telef%C3%B3nicos-y-guias
2025-05-30 17:20:51 - YouTubeScraper - INFO - ‚úÖ Extraction completed. Total results: 2
2025-05-30 17:20:51 - YouTubeScraper - INFO - üìä Success rate: 50.0% (1/2)
2025-05-30 17:20:51 - YouTubeScraper - DEBUG - Results preview: [
  {
    "metadata": {
      "source": {
        "name": "DIRECTORIOS TELEF\u00d3NICOS Y GUIAS en Republica Dominicana | P\u00e1ginas Amarillas",
        "url": "https://paginasamarillas.com.do/en/business/search/republica-dominicana/c/directorios-telef%C3%B3nicos-y-guias",
        "type": "Business Directory",
        "summary": "This page lists telephone directories and guides available in the Dominican Republic. It provides contact information and locations for businesses in this category."
      },
      "result": {
        "success": true,
        "entities_found": 4,
        "error": null,
        "error_details": null
      },
      "relevant_urls": [
        {
          "title": "View Map",
          "reason": "May contain additional location data for businesses in the Dominican Republic.",
          "url": "/en/business/search-map/republica-dominicana/directorios-telef%C3%B3nicos-y-guias"
        },
        {
          "title": "C\u00f3mo Anunciarte",
          "reason": "Thi...
2025-05-30 17:20:51 - YouTubeScraper - INFO - üíæ Saved website data: 4 raw items, 8 cleaned entities
2025-05-30 17:20:51 - YouTubeScraper - INFO - üìÅ Results saved to output files
2025-05-30 17:20:51 - YouTubeScraper - INFO - ‚úÖ Complete pipeline finished in 15.04 seconds. Successful extractions: 1/2
2025-05-30 17:20:51 - YouTubeScraper - INFO - Website scraping completed. Processed 2 websites.
2025-05-30 17:30:48 - YouTubeScraper - INFO - Loaded 1 items from input/search_urls_list.json
2025-05-30 17:30:48 - YouTubeScraper - INFO - Initialized SearchResultsScraper with configuration
2025-05-30 17:30:48 - YouTubeScraper - DEBUG - Scraping config: SearchScrapingConfig(max_concurrent_searches=3, search_delay_seconds=2.0, default_results_per_page=50, enable_stealth_mode=True, timeout_seconds=30)
2025-05-30 17:30:48 - YouTubeScraper - INFO - üöÄ Starting business URL extraction from search results
2025-05-30 17:30:48 - YouTubeScraper - INFO - Scraping 1 search result pages
2025-05-30 17:30:48 - YouTubeScraper - INFO - Starting batch scraping of 1 search URLs
2025-05-30 17:30:50 - YouTubeScraper - INFO - Browser launched successfully
2025-05-30 17:30:50 - YouTubeScraper - INFO - Processing batch 1/1 (1 URLs)
2025-05-30 17:30:50 - YouTubeScraper - DEBUG - Starting scrape for search URL: www.google.com/search
2025-05-30 17:30:50 - YouTubeScraper - DEBUG - Applied stealth mode to browser page
2025-05-30 17:30:57 - YouTubeScraper - INFO - Scrolling to load content for https://www.google.com/search?q=restaurantes+zona+colonial&num=50&cr=countryDO&gl=DO&start=0&tbs=lr%3Alang_1en&sei=-6Q5aIbvL6vEwPAPw_KNkQQ
2025-05-30 17:30:57 - YouTubeScraper - INFO - Scrolling down (5 steps)
2025-05-30 17:31:01 - YouTubeScraper - INFO - Scrolling back to top
2025-05-30 17:31:03 - YouTubeScraper - INFO - Successfully captured HTML from https://www.google.com/search?q=restaurantes+zona+colonial&num=50&cr=countryDO&gl=DO&start=0&tbs=lr%3Alang_1en (length: 933176).
2025-05-30 17:31:04 - YouTubeScraper - DEBUG - Processed HTML - Cleaned: 218218 chars
2025-05-30 17:31:04 - YouTubeScraper - DEBUG - Processed HTML - LLM-friendly: 32574 chars
2025-05-30 17:31:04 - YouTubeScraper - INFO - ‚úÖ Successfully scraped search results from: www.google.com/search
2025-05-30 17:31:04 - YouTubeScraper - INFO - Browser closed successfully
2025-05-30 17:31:04 - YouTubeScraper - INFO - ‚úÖ Batch scraping completed. Success rate: 100.0% (1/1)
2025-05-30 17:31:04 - YouTubeScraper - INFO - üíæ Saved debug file for LLM to 'debug_files/search_scraping/temp_processed_data (2025-05-30_17-31-04).json'
2025-05-30 17:31:04 - YouTubeScraper - DEBUG - Scraping results saved to debug files
2025-05-30 17:31:04 - YouTubeScraper - INFO - Initializing LLM-based URL extraction
2025-05-30 17:31:05 - YouTubeScraper - INFO - Initialized LLMDataExtractor with 1 input items
2025-05-30 17:31:05 - YouTubeScraper - INFO - Schema type: search
2025-05-30 17:31:05 - YouTubeScraper - INFO - Executing LLM extraction using method: crawl4ai
2025-05-30 17:31:05 - YouTubeScraper - INFO - Starting extraction of 1 items using method: crawl4ai
2025-05-30 17:31:05 - YouTubeScraper - INFO - Schema type: search
2025-05-30 17:31:05 - YouTubeScraper - INFO - Processing batch 1/1 with 1 items
2025-05-30 17:31:05 - YouTubeScraper - INFO - Starting Crawl4AI extraction for URL: 'https://www.google.com/search?q=restaurantes+zona+colonial&num=50&cr=countryDO&gl=DO&start=0&tbs=lr%3Alang_1en'
2025-05-30 17:31:20 - YouTubeScraper - DEBUG - Processed array response by selecting first valid element
2025-05-30 17:31:20 - YouTubeScraper - INFO - ‚úÖ Successfully extracted and validated data via Crawl4AI for URL: https://www.google.com/search?q=restaurantes+zona+colonial&num=50&cr=countryDO&gl=DO&start=0&tbs=lr%3Alang_1en
2025-05-30 17:31:20 - YouTubeScraper - INFO - ‚úÖ Extraction completed. Total results: 1
2025-05-30 17:31:20 - YouTubeScraper - INFO - üìä Success rate: 100.0% (1/1)
2025-05-30 17:31:20 - YouTubeScraper - DEBUG - Results preview: [
  {
    "metadata": {
      "context": {
        "query": "restaurantes zona colonial",
        "url": "https://www.google.com/search?q=restaurantes+zona+colonial&num=50&cr=countryDO&gl=DO&start=0&tbs=lr%3Alang_1en",
        "results": 50
      },
      "result": {
        "success": true,
        "urls_found": 15,
        "error": null,
        "error_details": null
      }
    },
    "urls": [
      {
        "title": "Ocho restaurantes donde comer en la Zona Colonial Diario Librehttps://www.diariolibre.com \u203a revista \u203a cultura \u203a ocho-re...",
        "reason": "Article about restaurants in Zona Colonial, DR",
        "url": "https://www.diariolibre.com/revista/cultura/ocho-restaurantes-donde-comer-en-la-zona-colonial-GD27244772"
      },
      {
        "title": "Ocho restaurantes donde comer en la Zona Colonial elpaisaldia.dohttps://elpaisaldia.do \u203a Destacados",
        "reason": "Article about restaurants in Zona Colonial, DR",
        "url": "https://elpaisald...
2025-05-30 17:31:20 - YouTubeScraper - INFO - ‚úÖ Extraction completed successfully
2025-05-30 17:31:20 - YouTubeScraper - INFO - üìä Results: 1 search results processed
2025-05-30 17:31:20 - YouTubeScraper - INFO - üìä Total business URLs extracted: 15
2025-05-30 17:31:20 - YouTubeScraper - INFO - üíæ Saved search data: 1 raw items, 15 cleaned entities
2025-05-30 17:31:20 - YouTubeScraper - DEBUG - Final extraction results saved to debug files
2025-05-30 18:53:15 - YouTubeScraper - INFO - Loaded 1 items from input/search_urls_list.json
2025-05-30 18:53:15 - YouTubeScraper - INFO - Initialized SearchResultsScraper with configuration
2025-05-30 18:53:15 - YouTubeScraper - DEBUG - Scraping config: SearchScrapingConfig(max_concurrent_searches=3, search_delay_seconds=2.0, default_results_per_page=50, enable_stealth_mode=True, timeout_seconds=30)
2025-05-30 18:53:15 - YouTubeScraper - INFO - üöÄ Starting business URL extraction from search results
2025-05-30 18:53:15 - YouTubeScraper - INFO - Scraping 1 search result pages
2025-05-30 18:53:15 - YouTubeScraper - INFO - Starting batch scraping of 1 search URLs
2025-05-30 18:53:36 - YouTubeScraper - INFO - Browser launched successfully
2025-05-30 18:53:36 - YouTubeScraper - INFO - Processing batch 1/1 (1 URLs)
2025-05-30 18:53:36 - YouTubeScraper - DEBUG - Starting scrape for search URL: lazybuguru.lt/
2025-05-30 18:53:37 - YouTubeScraper - DEBUG - Applied stealth mode to browser page
2025-05-30 18:53:44 - YouTubeScraper - INFO - Scrolling to load content for https://lazybuguru.lt/
2025-05-30 18:53:44 - YouTubeScraper - INFO - Scrolling down (5 steps)
2025-05-30 18:53:48 - YouTubeScraper - WARNING - Error during scrolling: Page.evaluate: Target page, context or browser has been closed
Traceback (most recent call last):
  File "d:\Web Scraping\Client Projects\yogi291\Project2 AI Agent Web Scraper\ai_powered_bussineses_data_crawler\utils\helpers.py", line 72, in _scroll_and_for_content
    new_height = await page.evaluate("document.body.scrollHeight")
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "d:\Web Scraping\Client Projects\yogi291\Project2 AI Agent Web Scraper\ai_powered_bussineses_data_crawler\.venv\Lib\site-packages\playwright\async_api\_generated.py", line 8513, in evaluate
    await self._impl_obj.evaluate(
        expression=expression, arg=mapping.to_impl(arg)
    )
  File "d:\Web Scraping\Client Projects\yogi291\Project2 AI Agent Web Scraper\ai_powered_bussineses_data_crawler\.venv\Lib\site-packages\playwright\_impl\_page.py", line 468, in evaluate
    return await self._main_frame.evaluate(expression, arg)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "d:\Web Scraping\Client Projects\yogi291\Project2 AI Agent Web Scraper\ai_powered_bussineses_data_crawler\.venv\Lib\site-packages\playwright\_impl\_frame.py", line 278, in evaluate
    await self._channel.send(
    ...<5 lines>...
    )
  File "d:\Web Scraping\Client Projects\yogi291\Project2 AI Agent Web Scraper\ai_powered_bussineses_data_crawler\.venv\Lib\site-packages\playwright\_impl\_connection.py", line 61, in send
    return await self._connection.wrap_api_call(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<2 lines>...
    )
    ^
  File "d:\Web Scraping\Client Projects\yogi291\Project2 AI Agent Web Scraper\ai_powered_bussineses_data_crawler\.venv\Lib\site-packages\playwright\_impl\_connection.py", line 528, in wrap_api_call
    raise rewrite_error(error, f"{parsed_st['apiName']}: {error}") from None
playwright._impl._errors.TargetClosedError: Page.evaluate: Target page, context or browser has been closed
2025-05-30 18:53:48 - YouTubeScraper - ERROR - Unexpected error during HTML capture for https://lazybuguru.lt/: Page.content: Target page, context or browser has been closed
Traceback (most recent call last):
  File "d:\Web Scraping\Client Projects\yogi291\Project2 AI Agent Web Scraper\ai_powered_bussineses_data_crawler\utils\helpers.py", line 113, in get_html_content
    raw_html = await page.content()
               ^^^^^^^^^^^^^^^^^^^^
  File "d:\Web Scraping\Client Projects\yogi291\Project2 AI Agent Web Scraper\ai_powered_bussineses_data_crawler\.venv\Lib\site-packages\playwright\async_api\_generated.py", line 8889, in content
    return mapping.from_maybe_impl(await self._impl_obj.content())
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "d:\Web Scraping\Client Projects\yogi291\Project2 AI Agent Web Scraper\ai_powered_bussineses_data_crawler\.venv\Lib\site-packages\playwright\_impl\_page.py", line 535, in content
    return await self._main_frame.content()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "d:\Web Scraping\Client Projects\yogi291\Project2 AI Agent Web Scraper\ai_powered_bussineses_data_crawler\.venv\Lib\site-packages\playwright\_impl\_frame.py", line 416, in content
    return await self._channel.send("content")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "d:\Web Scraping\Client Projects\yogi291\Project2 AI Agent Web Scraper\ai_powered_bussineses_data_crawler\.venv\Lib\site-packages\playwright\_impl\_connection.py", line 61, in send
    return await self._connection.wrap_api_call(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<2 lines>...
    )
    ^
  File "d:\Web Scraping\Client Projects\yogi291\Project2 AI Agent Web Scraper\ai_powered_bussineses_data_crawler\.venv\Lib\site-packages\playwright\_impl\_connection.py", line 528, in wrap_api_call
    raise rewrite_error(error, f"{parsed_st['apiName']}: {error}") from None
playwright._impl._errors.TargetClosedError: Page.content: Target page, context or browser has been closed
2025-05-30 18:53:48 - YouTubeScraper - ERROR - ‚ùå Unexpected error during search scraping: cannot access local variable 'raw_html' where it is not associated with a value for URL: lazybuguru.lt/
2025-05-30 18:53:48 - YouTubeScraper - DEBUG - Scraping error traceback: Traceback (most recent call last):
  File "d:\Web Scraping\Client Projects\yogi291\Project2 AI Agent Web Scraper\ai_powered_bussineses_data_crawler\utils\helpers.py", line 113, in get_html_content
    raw_html = await page.content()
               ^^^^^^^^^^^^^^^^^^^^
  File "d:\Web Scraping\Client Projects\yogi291\Project2 AI Agent Web Scraper\ai_powered_bussineses_data_crawler\.venv\Lib\site-packages\playwright\async_api\_generated.py", line 8889, in content
    return mapping.from_maybe_impl(await self._impl_obj.content())
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "d:\Web Scraping\Client Projects\yogi291\Project2 AI Agent Web Scraper\ai_powered_bussineses_data_crawler\.venv\Lib\site-packages\playwright\_impl\_page.py", line 535, in content
    return await self._main_frame.content()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "d:\Web Scraping\Client Projects\yogi291\Project2 AI Agent Web Scraper\ai_powered_bussineses_data_crawler\.venv\Lib\site-packages\playwright\_impl\_frame.py", line 416, in content
    return await self._channel.send("content")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "d:\Web Scraping\Client Projects\yogi291\Project2 AI Agent Web Scraper\ai_powered_bussineses_data_crawler\.venv\Lib\site-packages\playwright\_impl\_connection.py", line 61, in send
    return await self._connection.wrap_api_call(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<2 lines>...
    )
    ^
  File "d:\Web Scraping\Client Projects\yogi291\Project2 AI Agent Web Scraper\ai_powered_bussineses_data_crawler\.venv\Lib\site-packages\playwright\_impl\_connection.py", line 528, in wrap_api_call
    raise rewrite_error(error, f"{parsed_st['apiName']}: {error}") from None
playwright._impl._errors.TargetClosedError: Page.content: Target page, context or browser has been closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\Web Scraping\Client Projects\yogi291\Project2 AI Agent Web Scraper\ai_powered_bussineses_data_crawler\scrapers\searches_scraping.py", line 230, in _scrape_single_search_result
    raw_html_content, http_status_code = await self.playwright_browser.get_html_content(
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<2 lines>...
    )
    ^
  File "d:\Web Scraping\Client Projects\yogi291\Project2 AI Agent Web Scraper\ai_powered_bussineses_data_crawler\utils\helpers.py", line 164, in get_html_content
    return raw_html, status_code
           ^^^^^^^^
UnboundLocalError: cannot access local variable 'raw_html' where it is not associated with a value

2025-05-30 18:53:49 - YouTubeScraper - INFO - Browser closed successfully
2025-05-30 18:53:49 - YouTubeScraper - INFO - ‚úÖ Batch scraping completed. Success rate: 0.0% (0/1)
2025-05-30 18:53:49 - YouTubeScraper - INFO - üíæ Saved debug file for LLM to 'debug_files/search_scraping/temp_processed_data (2025-05-30_18-53-49).json'
2025-05-30 18:53:49 - YouTubeScraper - DEBUG - Scraping results saved to debug files
2025-05-30 18:53:49 - YouTubeScraper - INFO - Initializing LLM-based URL extraction
2025-05-30 18:53:49 - YouTubeScraper - INFO - Initialized LLMDataExtractor with 1 input items
2025-05-30 18:53:49 - YouTubeScraper - INFO - Schema type: search
2025-05-30 18:53:49 - YouTubeScraper - INFO - Executing LLM extraction using method: crawl4ai
2025-05-30 18:53:49 - YouTubeScraper - INFO - Starting extraction of 1 items using method: crawl4ai
2025-05-30 18:53:49 - YouTubeScraper - INFO - Schema type: search
2025-05-30 18:53:49 - YouTubeScraper - INFO - Processing batch 1/1 with 1 items
2025-05-30 18:53:49 - YouTubeScraper - INFO - Starting Crawl4AI extraction for URL: 'https://lazybuguru.lt/'
2025-05-30 18:53:49 - YouTubeScraper - ERROR - Batch 1 processing failed: Connection closed while reading from the driver
2025-05-30 18:54:52 - YouTubeScraper - INFO - Loaded 1 items from input/search_urls_list.json
2025-05-30 18:54:52 - YouTubeScraper - INFO - Initialized SearchResultsScraper with configuration
2025-05-30 18:54:52 - YouTubeScraper - DEBUG - Scraping config: SearchScrapingConfig(max_concurrent_searches=3, search_delay_seconds=2.0, default_results_per_page=50, enable_stealth_mode=True, timeout_seconds=30)
2025-05-30 18:54:52 - YouTubeScraper - INFO - üöÄ Starting business URL extraction from search results
2025-05-30 18:54:52 - YouTubeScraper - INFO - Scraping 1 search result pages
2025-05-30 18:54:52 - YouTubeScraper - INFO - Starting batch scraping of 1 search URLs
2025-05-30 18:54:53 - YouTubeScraper - INFO - Browser launched successfully
2025-05-30 18:54:53 - YouTubeScraper - INFO - Processing batch 1/1 (1 URLs)
2025-05-30 18:54:53 - YouTubeScraper - DEBUG - Starting scrape for search URL: lazybuguru.lt/
2025-05-30 18:54:53 - YouTubeScraper - DEBUG - Applied stealth mode to browser page
2025-05-30 18:55:00 - YouTubeScraper - INFO - Scrolling to load content for https://lazybuguru.lt/
2025-05-30 18:55:01 - YouTubeScraper - INFO - Scrolling down (5 steps)
2025-05-30 18:55:05 - YouTubeScraper - INFO - Scrolling back to top
2025-05-30 18:55:06 - YouTubeScraper - INFO - Successfully captured HTML from https://lazybuguru.lt/ (length: 399190).
2025-05-30 18:55:07 - YouTubeScraper - DEBUG - Processed HTML - Cleaned: 83288 chars
2025-05-30 18:55:07 - YouTubeScraper - DEBUG - Processed HTML - LLM-friendly: 13593 chars
2025-05-30 18:55:07 - YouTubeScraper - INFO - ‚úÖ Successfully scraped search results from: lazybuguru.lt/
2025-05-30 18:55:07 - YouTubeScraper - INFO - Browser closed successfully
2025-05-30 18:55:07 - YouTubeScraper - INFO - ‚úÖ Batch scraping completed. Success rate: 100.0% (1/1)
2025-05-30 18:55:07 - YouTubeScraper - INFO - üíæ Saved debug file for LLM to 'debug_files/search_scraping/temp_processed_data (2025-05-30_18-55-07).json'
2025-05-30 18:55:07 - YouTubeScraper - DEBUG - Scraping results saved to debug files
2025-05-30 18:55:07 - YouTubeScraper - INFO - Initializing LLM-based URL extraction
2025-05-30 18:55:07 - YouTubeScraper - INFO - Initialized LLMDataExtractor with 1 input items
2025-05-30 18:55:07 - YouTubeScraper - INFO - Schema type: search
2025-05-30 18:55:07 - YouTubeScraper - INFO - Executing LLM extraction using method: crawl4ai
2025-05-30 18:55:07 - YouTubeScraper - INFO - Starting extraction of 1 items using method: crawl4ai
2025-05-30 18:55:07 - YouTubeScraper - INFO - Schema type: search
2025-05-30 18:55:07 - YouTubeScraper - INFO - Processing batch 1/1 with 1 items
2025-05-30 18:55:07 - YouTubeScraper - INFO - Starting Crawl4AI extraction for URL: 'https://lazybuguru.lt/'
2025-05-30 18:55:12 - YouTubeScraper - DEBUG - Processed array response by selecting first valid element
2025-05-30 18:55:12 - YouTubeScraper - INFO - ‚úÖ Successfully extracted and validated data via Crawl4AI for URL: https://lazybuguru.lt/
2025-05-30 21:52:30 - YouTubeScraper - INFO - üöÄ Starting test execution of SearchResultsScraper
2025-05-30 21:52:30 - YouTubeScraper - INFO - Initialized SearchResultsScraper with configuration
2025-05-30 21:52:30 - YouTubeScraper - DEBUG - Scraping config: SearchScrapingConfig(max_concurrent_searches=2, search_delay_seconds=2.0, default_results_per_page=50, enable_stealth_mode=True, timeout_seconds=30)
2025-05-30 21:52:30 - YouTubeScraper - INFO - üöÄ Starting business URL extraction from search results
2025-05-30 21:52:30 - YouTubeScraper - INFO - Generating search URLs from 3 search terms
2025-05-30 21:52:30 - YouTubeScraper - DEBUG - Generating search URL for term: 'restaurantes zona colonial'
2025-05-30 21:52:30 - YouTubeScraper - INFO - Generated search URL for 'restaurantes zona colonial' with 50 results
2025-05-30 21:52:30 - YouTubeScraper - DEBUG - Complete URL: https://www.google.com/search?q=restaurantes+zona+colonial&num=50&cr=countryDO&gl=DO&start=0&tbs=lr%3Alang_1en
2025-05-30 21:52:30 - YouTubeScraper - DEBUG - Generating search URL for term: 'hoteles santo domingo'
2025-05-30 21:52:30 - YouTubeScraper - INFO - Generated search URL for 'hoteles santo domingo' with 50 results
2025-05-30 21:52:30 - YouTubeScraper - DEBUG - Complete URL: https://www.google.com/search?q=hoteles+santo+domingo&num=50&cr=countryDO&gl=DO&start=0&tbs=lr%3Alang_1en
2025-05-30 21:52:31 - YouTubeScraper - DEBUG - Generating search URL for term: 'servicios turisticos punta cana'
2025-05-30 21:52:31 - YouTubeScraper - INFO - Generated search URL for 'servicios turisticos punta cana' with 50 results
2025-05-30 21:52:31 - YouTubeScraper - DEBUG - Complete URL: https://www.google.com/search?q=servicios+turisticos+punta+cana&num=50&cr=countryDO&gl=DO&start=0&tbs=lr%3Alang_1en
2025-05-30 21:52:31 - YouTubeScraper - INFO - Generated 3 search URLs
2025-05-30 21:52:31 - YouTubeScraper - INFO - Scraping 3 search result pages
2025-05-30 21:52:31 - YouTubeScraper - INFO - Starting batch scraping of 3 search URLs
2025-05-30 21:52:31 - YouTubeScraper - INFO - Processing batch 1/2 (2 URLs)
2025-05-30 21:52:31 - YouTubeScraper - ERROR - SeleniumBase scraping error: SB() got an unexpected keyword argument 'timeout'
2025-05-30 21:52:31 - YouTubeScraper - ERROR - SeleniumBase scraping error: SB() got an unexpected keyword argument 'timeout'
2025-05-30 21:52:31 - YouTubeScraper - DEBUG - Traceback (most recent call last):
  File "d:\Web Scraping\Client Projects\yogi291\Project2 AI Agent Web Scraper\ai_powered_bussineses_data_crawler\utils\helpers.py", line 70, in _scrape_with_seleniumbase
    with SB(
         ~~^
        uc=True,
        ^^^^^^^^
    ...<4 lines>...
        timeout=60  # 60 second timeout
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ) as sb:
    ^
  File "C:\Users\anasf\AppData\Local\Programs\Python\Python313\Lib\contextlib.py", line 305, in helper
    return _GeneratorContextManager(func, args, kwds)
  File "C:\Users\anasf\AppData\Local\Programs\Python\Python313\Lib\contextlib.py", line 109, in __init__
    self.gen = func(*args, **kwds)
               ~~~~^^^^^^^^^^^^^^^
TypeError: SB() got an unexpected keyword argument 'timeout'

2025-05-30 21:52:31 - YouTubeScraper - DEBUG - Traceback (most recent call last):
  File "d:\Web Scraping\Client Projects\yogi291\Project2 AI Agent Web Scraper\ai_powered_bussineses_data_crawler\utils\helpers.py", line 70, in _scrape_with_seleniumbase
    with SB(
         ~~^
        uc=True,
        ^^^^^^^^
    ...<4 lines>...
        timeout=60  # 60 second timeout
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ) as sb:
    ^
  File "C:\Users\anasf\AppData\Local\Programs\Python\Python313\Lib\contextlib.py", line 305, in helper
    return _GeneratorContextManager(func, args, kwds)
  File "C:\Users\anasf\AppData\Local\Programs\Python\Python313\Lib\contextlib.py", line 109, in __init__
    self.gen = func(*args, **kwds)
               ~~~~^^^^^^^^^^^^^^^
TypeError: SB() got an unexpected keyword argument 'timeout'

2025-05-30 21:52:31 - YouTubeScraper - WARNING - ‚ùå Failed to retrieve HTML content (Status: UNEXPECTED_ERROR: SB() got an unexpected keyword argument 'timeout') for URL: www.google.com/search
2025-05-30 21:52:31 - YouTubeScraper - WARNING - ‚ùå Failed to retrieve HTML content (Status: UNEXPECTED_ERROR: SB() got an unexpected keyword argument 'timeout') for URL: www.google.com/search
2025-05-30 21:52:31 - YouTubeScraper - DEBUG - Inter-batch delay: 2.0s
2025-05-30 21:52:33 - YouTubeScraper - INFO - Processing batch 2/2 (1 URLs)
2025-05-30 21:52:33 - YouTubeScraper - ERROR - SeleniumBase scraping error: SB() got an unexpected keyword argument 'timeout'
2025-05-30 21:52:33 - YouTubeScraper - DEBUG - Traceback (most recent call last):
  File "d:\Web Scraping\Client Projects\yogi291\Project2 AI Agent Web Scraper\ai_powered_bussineses_data_crawler\utils\helpers.py", line 70, in _scrape_with_seleniumbase
    with SB(
         ~~^
        uc=True,
        ^^^^^^^^
    ...<4 lines>...
        timeout=60  # 60 second timeout
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ) as sb:
    ^
  File "C:\Users\anasf\AppData\Local\Programs\Python\Python313\Lib\contextlib.py", line 305, in helper
    return _GeneratorContextManager(func, args, kwds)
  File "C:\Users\anasf\AppData\Local\Programs\Python\Python313\Lib\contextlib.py", line 109, in __init__
    self.gen = func(*args, **kwds)
               ~~~~^^^^^^^^^^^^^^^
TypeError: SB() got an unexpected keyword argument 'timeout'

2025-05-30 21:52:33 - YouTubeScraper - WARNING - ‚ùå Failed to retrieve HTML content (Status: UNEXPECTED_ERROR: SB() got an unexpected keyword argument 'timeout') for URL: www.google.com/search
2025-05-30 21:52:33 - YouTubeScraper - INFO - ‚úÖ Batch scraping completed. Success rate: 0.0% (0/3)
2025-05-30 21:52:33 - YouTubeScraper - INFO - üíæ Saved debug file for LLM to 'debug_files/search_scraping/temp_processed_data (2025-05-30_21-52-33).json'
2025-05-30 21:52:33 - YouTubeScraper - DEBUG - Scraping results saved to debug files
2025-05-30 21:52:33 - YouTubeScraper - INFO - Initializing LLM-based URL extraction
2025-05-30 21:52:33 - YouTubeScraper - INFO - Initialized LLMDataExtractor with 3 input items
2025-05-30 21:52:33 - YouTubeScraper - INFO - Schema type: search
2025-05-30 21:52:33 - YouTubeScraper - INFO - Executing LLM extraction using method: crawl4ai
2025-05-30 21:52:33 - YouTubeScraper - INFO - Starting extraction of 3 items using method: crawl4ai
2025-05-30 21:52:33 - YouTubeScraper - INFO - Schema type: search
2025-05-30 21:52:33 - YouTubeScraper - INFO - Processing batch 1/1 with 3 items
2025-05-30 21:52:33 - YouTubeScraper - INFO - Starting Crawl4AI extraction for URL: 'https://www.google.com/search?q=restaurantes+zona+colonial&num=50&cr=countryDO&gl=DO&start=0&tbs=lr%3Alang_1en'
2025-05-30 21:52:33 - YouTubeScraper - INFO - Starting Crawl4AI extraction for URL: 'https://www.google.com/search?q=hoteles+santo+domingo&num=50&cr=countryDO&gl=DO&start=0&tbs=lr%3Alang_1en'
2025-05-30 21:52:33 - YouTubeScraper - INFO - Starting Crawl4AI extraction for URL: 'https://www.google.com/search?q=servicios+turisticos+punta+cana&num=50&cr=countryDO&gl=DO&start=0&tbs=lr%3Alang_1en'
2025-05-30 21:53:01 - YouTubeScraper - ERROR - Invalid array structure in LLM response
2025-05-30 21:53:01 - YouTubeScraper - DEBUG - Response preview: [
    {
        "index": 0,
        "error": true,
        "tags": [
            "error"
        ],
        "content": "'str' object has no attribute 'choices'"
    }
]...
2025-05-30 21:53:05 - YouTubeScraper - DEBUG - Processed array response by selecting first valid element
2025-05-30 21:53:05 - YouTubeScraper - INFO - ‚úÖ Successfully extracted and validated data via Crawl4AI for URL: https://www.google.com/search?q=hoteles+santo+domingo&num=50&cr=countryDO&gl=DO&start=0&tbs=lr%3Alang_1en
2025-05-30 21:53:05 - YouTubeScraper - ERROR - Batch 1 processing failed: BrowserType.launch: Target page, context or browser has been closed
Browser logs:

<launching> C:\Users\anasf\AppData\Local\ms-playwright\chromium-1169\chrome-win\chrome.exe --disable-field-trial-config --disable-background-networking --disable-background-timer-throttling --disable-backgrounding-occluded-windows --disable-back-forward-cache --disable-breakpad --disable-client-side-phishing-detection --disable-component-extensions-with-background-pages --disable-component-update --no-default-browser-check --disable-default-apps --disable-dev-shm-usage --disable-extensions --disable-features=AcceptCHFrame,AutoExpandDetailsElement,AvoidUnnecessaryBeforeUnloadCheckSync,CertificateTransparencyComponentUpdater,DeferRendererTasksAfterInput,DestroyProfileOnBrowserClose,DialMediaRouteProvider,ExtensionManifestV2Disabled,GlobalMediaControls,HttpsUpgrades,ImprovedCookieControls,LazyFrameLoading,LensOverlay,MediaRouter,PaintHolding,ThirdPartyStoragePartitioning,Translate --allow-pre-commit-input --disable-hang-monitor --disable-ipc-flooding-protection --disable-popup-blocking --disable-prompt-on-repost --disable-renderer-backgrounding --force-color-profile=srgb --metrics-recording-only --no-first-run --enable-automation --password-store=basic --use-mock-keychain --no-service-autorun --export-tagged-pdf --disable-search-engine-choice-screen --unsafely-disable-devtools-self-xss-warnings --no-sandbox --disable-gpu --disable-gpu-compositing --disable-software-rasterizer --no-sandbox --disable-dev-shm-usage --no-first-run --no-default-browser-check --disable-infobars --window-position=0,0 --ignore-certificate-errors --ignore-certificate-errors-spki-list --disable-blink-features=AutomationControlled --window-position=400,0 --disable-renderer-backgrounding --disable-ipc-flooding-protection --force-color-profile=srgb --mute-audio --disable-background-timer-throttling --window-size=1080,600 --user-data-dir=C:\Users\anasf\AppData\Local\Temp\playwright_chromiumdev_profile-PiSXAz --remote-debugging-pipe --no-startup-window
<launched> pid=23100
[pid=23100] <gracefully close start>
Call log:
  - <launching> C:\Users\anasf\AppData\Local\ms-playwright\chromium-1169\chrome-win\chrome.exe --disable-field-trial-config --disable-background-networking --disable-background-timer-throttling --disable-backgrounding-occluded-windows --disable-back-forward-cache --disable-breakpad --disable-client-side-phishing-detection --disable-component-extensions-with-background-pages --disable-component-update --no-default-browser-check --disable-default-apps --disable-dev-shm-usage --disable-extensions --disable-features=AcceptCHFrame,AutoExpandDetailsElement,AvoidUnnecessaryBeforeUnloadCheckSync,CertificateTransparencyComponentUpdater,DeferRendererTasksAfterInput,DestroyProfileOnBrowserClose,DialMediaRouteProvider,ExtensionManifestV2Disabled,GlobalMediaControls,HttpsUpgrades,ImprovedCookieControls,LazyFrameLoading,LensOverlay,MediaRouter,PaintHolding,ThirdPartyStoragePartitioning,Translate --allow-pre-commit-input --disable-hang-monitor --disable-ipc-flooding-protection --disable-popup-blocking --disable-prompt-on-repost --disable-renderer-backgrounding --force-color-profile=srgb --metrics-recording-only --no-first-run --enable-automation --password-store=basic --use-mock-keychain --no-service-autorun --export-tagged-pdf --disable-search-engine-choice-screen --unsafely-disable-devtools-self-xss-warnings --no-sandbox --disable-gpu --disable-gpu-compositing --disable-software-rasterizer --no-sandbox --disable-dev-shm-usage --no-first-run --no-default-browser-check --disable-infobars --window-position=0,0 --ignore-certificate-errors --ignore-certificate-errors-spki-list --disable-blink-features=AutomationControlled --window-position=400,0 --disable-renderer-backgrounding --disable-ipc-flooding-protection --force-color-profile=srgb --mute-audio --disable-background-timer-throttling --window-size=1080,600 --user-data-dir=C:\Users\anasf\AppData\Local\Temp\playwright_chromiumdev_profile-PiSXAz --remote-debugging-pipe --no-startup-window
  - <launched> pid=23100
  - [pid=23100] <gracefully close start>

2025-05-30 21:53:05 - YouTubeScraper - DEBUG - Batch error traceback: Traceback (most recent call last):
  File "d:\Web Scraping\Client Projects\yogi291\Project2 AI Agent Web Scraper\ai_powered_bussineses_data_crawler\scrapers\llm_data_extraction.py", line 581, in execute_data_extraction
    batch_results = await self._process_extraction_batch(current_batch, extraction_method)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "d:\Web Scraping\Client Projects\yogi291\Project2 AI Agent Web Scraper\ai_powered_bussineses_data_crawler\scrapers\llm_data_extraction.py", line 493, in _process_extraction_batch
    return await asyncio.gather(*extraction_tasks)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "d:\Web Scraping\Client Projects\yogi291\Project2 AI Agent Web Scraper\ai_powered_bussineses_data_crawler\scrapers\llm_data_extraction.py", line 327, in _extract_via_crawl4ai
    async with AsyncWebCrawler(config=self.crawl4ai_config.browser_config) as crawler:
               ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "d:\Web Scraping\Client Projects\yogi291\Project2 AI Agent Web Scraper\ai_powered_bussineses_data_crawler\.venv\Lib\site-packages\crawl4ai\async_webcrawler.py", line 191, in __aenter__
    return await self.start()
           ^^^^^^^^^^^^^^^^^^
  File "d:\Web Scraping\Client Projects\yogi291\Project2 AI Agent Web Scraper\ai_powered_bussineses_data_crawler\.venv\Lib\site-packages\crawl4ai\async_webcrawler.py", line 174, in start
    await self.crawler_strategy.__aenter__()
  File "d:\Web Scraping\Client Projects\yogi291\Project2 AI Agent Web Scraper\ai_powered_bussineses_data_crawler\.venv\Lib\site-packages\crawl4ai\async_crawler_strategy.py", line 111, in __aenter__
    await self.start()
  File "d:\Web Scraping\Client Projects\yogi291\Project2 AI Agent Web Scraper\ai_powered_bussineses_data_crawler\.venv\Lib\site-packages\crawl4ai\async_crawler_strategy.py", line 121, in start
    await self.browser_manager.start()
  File "d:\Web Scraping\Client Projects\yogi291\Project2 AI Agent Web Scraper\ai_powered_bussineses_data_crawler\.venv\Lib\site-packages\crawl4ai\browser_manager.py", line 614, in start
    self.browser = await self.playwright.chromium.launch(**browser_args)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "d:\Web Scraping\Client Projects\yogi291\Project2 AI Agent Web Scraper\ai_powered_bussineses_data_crawler\.venv\Lib\site-packages\playwright\async_api\_generated.py", line 14451, in launch
    await self._impl_obj.launch(
    ...<17 lines>...
    )
  File "d:\Web Scraping\Client Projects\yogi291\Project2 AI Agent Web Scraper\ai_powered_bussineses_data_crawler\.venv\Lib\site-packages\playwright\_impl\_browser_type.py", line 97, in launch
    Browser, from_channel(await self._channel.send("launch", params))
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "d:\Web Scraping\Client Projects\yogi291\Project2 AI Agent Web Scraper\ai_powered_bussineses_data_crawler\.venv\Lib\site-packages\playwright\_impl\_connection.py", line 61, in send
    return await self._connection.wrap_api_call(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<2 lines>...
    )
    ^
  File "d:\Web Scraping\Client Projects\yogi291\Project2 AI Agent Web Scraper\ai_powered_bussineses_data_crawler\.venv\Lib\site-packages\playwright\_impl\_connection.py", line 528, in wrap_api_call
    raise rewrite_error(error, f"{parsed_st['apiName']}: {error}") from None
playwright._impl._errors.TargetClosedError: BrowserType.launch: Target page, context or browser has been closed
Browser logs:

<launching> C:\Users\anasf\AppData\Local\ms-playwright\chromium-1169\chrome-win\chrome.exe --disable-field-trial-config --disable-background-networking --disable-background-timer-throttling --disable-backgrounding-occluded-windows --disable-back-forward-cache --disable-breakpad --disable-client-side-phishing-detection --disable-component-extensions-with-background-pages --disable-component-update --no-default-browser-check --disable-default-apps --disable-dev-shm-usage --disable-extensions --disable-features=AcceptCHFrame,AutoExpandDetailsElement,AvoidUnnecessaryBeforeUnloadCheckSync,CertificateTransparencyComponentUpdater,DeferRendererTasksAfterInput,DestroyProfileOnBrowserClose,DialMediaRouteProvider,ExtensionManifestV2Disabled,GlobalMediaControls,HttpsUpgrades,ImprovedCookieControls,LazyFrameLoading,LensOverlay,MediaRouter,PaintHolding,ThirdPartyStoragePartitioning,Translate --allow-pre-commit-input --disable-hang-monitor --disable-ipc-flooding-protection --disable-popup-blocking --disable-prompt-on-repost --disable-renderer-backgrounding --force-color-profile=srgb --metrics-recording-only --no-first-run --enable-automation --password-store=basic --use-mock-keychain --no-service-autorun --export-tagged-pdf --disable-search-engine-choice-screen --unsafely-disable-devtools-self-xss-warnings --no-sandbox --disable-gpu --disable-gpu-compositing --disable-software-rasterizer --no-sandbox --disable-dev-shm-usage --no-first-run --no-default-browser-check --disable-infobars --window-position=0,0 --ignore-certificate-errors --ignore-certificate-errors-spki-list --disable-blink-features=AutomationControlled --window-position=400,0 --disable-renderer-backgrounding --disable-ipc-flooding-protection --force-color-profile=srgb --mute-audio --disable-background-timer-throttling --window-size=1080,600 --user-data-dir=C:\Users\anasf\AppData\Local\Temp\playwright_chromiumdev_profile-PiSXAz --remote-debugging-pipe --no-startup-window
<launched> pid=23100
[pid=23100] <gracefully close start>
Call log:
  - <launching> C:\Users\anasf\AppData\Local\ms-playwright\chromium-1169\chrome-win\chrome.exe --disable-field-trial-config --disable-background-networking --disable-background-timer-throttling --disable-backgrounding-occluded-windows --disable-back-forward-cache --disable-breakpad --disable-client-side-phishing-detection --disable-component-extensions-with-background-pages --disable-component-update --no-default-browser-check --disable-default-apps --disable-dev-shm-usage --disable-extensions --disable-features=AcceptCHFrame,AutoExpandDetailsElement,AvoidUnnecessaryBeforeUnloadCheckSync,CertificateTransparencyComponentUpdater,DeferRendererTasksAfterInput,DestroyProfileOnBrowserClose,DialMediaRouteProvider,ExtensionManifestV2Disabled,GlobalMediaControls,HttpsUpgrades,ImprovedCookieControls,LazyFrameLoading,LensOverlay,MediaRouter,PaintHolding,ThirdPartyStoragePartitioning,Translate --allow-pre-commit-input --disable-hang-monitor --disable-ipc-flooding-protection --disable-popup-blocking --disable-prompt-on-repost --disable-renderer-backgrounding --force-color-profile=srgb --metrics-recording-only --no-first-run --enable-automation --password-store=basic --use-mock-keychain --no-service-autorun --export-tagged-pdf --disable-search-engine-choice-screen --unsafely-disable-devtools-self-xss-warnings --no-sandbox --disable-gpu --disable-gpu-compositing --disable-software-rasterizer --no-sandbox --disable-dev-shm-usage --no-first-run --no-default-browser-check --disable-infobars --window-position=0,0 --ignore-certificate-errors --ignore-certificate-errors-spki-list --disable-blink-features=AutomationControlled --window-position=400,0 --disable-renderer-backgrounding --disable-ipc-flooding-protection --force-color-profile=srgb --mute-audio --disable-background-timer-throttling --window-size=1080,600 --user-data-dir=C:\Users\anasf\AppData\Local\Temp\playwright_chromiumdev_profile-PiSXAz --remote-debugging-pipe --no-startup-window
  - <launched> pid=23100
  - [pid=23100] <gracefully close start>


2025-05-30 21:53:05 - YouTubeScraper - INFO - ‚úÖ Extraction completed. Total results: 3
2025-05-30 21:53:05 - YouTubeScraper - INFO - üìä Success rate: 0.0% (0/3)
2025-05-30 21:53:05 - YouTubeScraper - DEBUG - Results preview: [
  {
    "metadata": {
      "context": {
        "query": "unknown",
        "url": "https://www.google.com/search?q=restaurantes+zona+colonial&num=50&cr=countryDO&gl=DO&start=0&tbs=lr%3Alang_1en",
        "results": 0
      },
      "result": {
        "success": false,
        "urls_found": 0,
        "error": "ExtractionError",
        "error_details": "Batch 1 processing failed: BrowserType.launch: Target page, context or browser has been closed\nBrowser logs:\n\n<launching> C:\\Users\\anasf\\AppData\\Local\\ms-playwright\\chromium-1169\\chrome-win\\chrome.exe --disable-field-trial-config --disable-background-networking --disable-background-timer-throttling --disable-backgrounding-occluded-windows --disable-back-forward-cache --disable-breakpad --disable-client-side-phishing-detection --disable-component-extensions-with-background-pages --disable-component-update --no-default-browser-check --disable-default-apps --disable-dev-shm-usage --disable-extensions --disable-features=Acce...
2025-05-30 21:53:05 - YouTubeScraper - INFO - ‚úÖ Extraction completed successfully
2025-05-30 21:53:05 - YouTubeScraper - INFO - üìä Results: 3 search results processed
2025-05-30 21:53:05 - YouTubeScraper - INFO - üìä Total business URLs extracted: 0
2025-05-30 21:53:05 - YouTubeScraper - INFO - üíæ Saved search data: 4 raw items, 15 cleaned entities
2025-05-30 21:53:05 - YouTubeScraper - DEBUG - Final extraction results saved to debug files
2025-05-30 21:53:05 - YouTubeScraper - INFO - ‚úÖ Test completed successfully
2025-05-30 21:53:05 - YouTubeScraper - INFO - üìä Processed 3 search results
2025-05-30 21:53:05 - YouTubeScraper - INFO - üìä Extracted 0 business URLs
2025-05-30 21:53:52 - YouTubeScraper - INFO - üöÄ Starting test execution of SearchResultsScraper
2025-05-30 21:53:52 - YouTubeScraper - INFO - Initialized SearchResultsScraper with configuration
2025-05-30 21:53:52 - YouTubeScraper - DEBUG - Scraping config: SearchScrapingConfig(max_concurrent_searches=2, search_delay_seconds=2.0, default_results_per_page=50, enable_stealth_mode=True, timeout_seconds=30)
2025-05-30 21:53:52 - YouTubeScraper - INFO - üöÄ Starting business URL extraction from search results
2025-05-30 21:53:52 - YouTubeScraper - INFO - Generating search URLs from 3 search terms
2025-05-30 21:53:52 - YouTubeScraper - DEBUG - Generating search URL for term: 'restaurantes zona colonial'
2025-05-30 21:53:52 - YouTubeScraper - INFO - Generated search URL for 'restaurantes zona colonial' with 50 results
2025-05-30 21:53:52 - YouTubeScraper - DEBUG - Complete URL: https://www.google.com/search?q=restaurantes+zona+colonial&num=50&cr=countryDO&gl=DO&start=0&tbs=lr%3Alang_1en
2025-05-30 21:53:52 - YouTubeScraper - DEBUG - Generating search URL for term: 'hoteles santo domingo'
2025-05-30 21:53:52 - YouTubeScraper - INFO - Generated search URL for 'hoteles santo domingo' with 50 results
2025-05-30 21:53:52 - YouTubeScraper - DEBUG - Complete URL: https://www.google.com/search?q=hoteles+santo+domingo&num=50&cr=countryDO&gl=DO&start=0&tbs=lr%3Alang_1en
2025-05-30 21:53:52 - YouTubeScraper - DEBUG - Generating search URL for term: 'servicios turisticos punta cana'
2025-05-30 21:53:52 - YouTubeScraper - INFO - Generated search URL for 'servicios turisticos punta cana' with 50 results
2025-05-30 21:53:52 - YouTubeScraper - DEBUG - Complete URL: https://www.google.com/search?q=servicios+turisticos+punta+cana&num=50&cr=countryDO&gl=DO&start=0&tbs=lr%3Alang_1en
2025-05-30 21:53:52 - YouTubeScraper - INFO - Generated 3 search URLs
2025-05-30 21:53:52 - YouTubeScraper - INFO - Scraping 3 search result pages
2025-05-30 21:53:52 - YouTubeScraper - INFO - Starting batch scraping of 3 search URLs
2025-05-30 21:53:52 - YouTubeScraper - INFO - Processing batch 1/2 (2 URLs)
2025-05-30 21:54:21 - YouTubeScraper - INFO - Successfully captured HTML (1440989 chars)
2025-05-30 21:54:23 - YouTubeScraper - INFO - Successfully captured HTML (1561614 chars)
2025-05-30 21:54:31 - YouTubeScraper - DEBUG - Processed HTML - LLM-friendly: 37187 chars
2025-05-30 21:54:31 - YouTubeScraper - INFO - ‚úÖ Successfully scraped search results from: www.google.com/search
2025-05-30 21:54:31 - YouTubeScraper - DEBUG - Processed HTML - LLM-friendly: 51772 chars
2025-05-30 21:54:31 - YouTubeScraper - INFO - ‚úÖ Successfully scraped search results from: www.google.com/search
2025-05-30 21:54:31 - YouTubeScraper - DEBUG - Inter-batch delay: 2.0s
2025-05-30 21:54:33 - YouTubeScraper - INFO - Processing batch 2/2 (1 URLs)
2025-05-30 21:54:50 - YouTubeScraper - INFO - Successfully captured HTML (2035177 chars)
2025-05-30 21:54:57 - YouTubeScraper - DEBUG - Processed HTML - LLM-friendly: 39832 chars
2025-05-30 21:54:57 - YouTubeScraper - INFO - ‚úÖ Successfully scraped search results from: www.google.com/search
2025-05-30 21:54:57 - YouTubeScraper - INFO - ‚úÖ Batch scraping completed. Success rate: 100.0% (3/3)
2025-05-30 21:54:57 - YouTubeScraper - INFO - üíæ Saved debug file for LLM to 'debug_files/search_scraping/temp_processed_data (2025-05-30_21-54-57).json'
2025-05-30 21:54:57 - YouTubeScraper - DEBUG - Scraping results saved to debug files
2025-05-30 21:54:57 - YouTubeScraper - INFO - Initializing LLM-based URL extraction
2025-05-30 21:54:57 - YouTubeScraper - INFO - Initialized LLMDataExtractor with 3 input items
2025-05-30 21:54:57 - YouTubeScraper - INFO - Schema type: search
2025-05-30 21:54:57 - YouTubeScraper - INFO - Executing LLM extraction using method: crawl4ai
2025-05-30 21:54:57 - YouTubeScraper - INFO - Starting extraction of 3 items using method: crawl4ai
2025-05-30 21:54:57 - YouTubeScraper - INFO - Schema type: search
2025-05-30 21:54:57 - YouTubeScraper - INFO - Processing batch 1/1 with 3 items
2025-05-30 21:54:57 - YouTubeScraper - INFO - Starting Crawl4AI extraction for URL: 'https://www.google.com/search?q=restaurantes+zona+colonial&num=50&cr=countryDO&gl=DO&start=0&tbs=lr%3Alang_1en'
2025-05-30 21:54:57 - YouTubeScraper - INFO - Starting Crawl4AI extraction for URL: 'https://www.google.com/search?q=hoteles+santo+domingo&num=50&cr=countryDO&gl=DO&start=0&tbs=lr%3Alang_1en'
2025-05-30 21:54:57 - YouTubeScraper - INFO - Starting Crawl4AI extraction for URL: 'https://www.google.com/search?q=servicios+turisticos+punta+cana&num=50&cr=countryDO&gl=DO&start=0&tbs=lr%3Alang_1en'
2025-05-30 21:55:11 - YouTubeScraper - DEBUG - Processed array response by selecting first valid element
2025-05-30 21:55:11 - YouTubeScraper - INFO - ‚úÖ Successfully extracted and validated data via Crawl4AI for URL: https://www.google.com/search?q=restaurantes+zona+colonial&num=50&cr=countryDO&gl=DO&start=0&tbs=lr%3Alang_1en
2025-05-30 21:55:18 - YouTubeScraper - DEBUG - Processed array response by selecting first valid element
2025-05-30 21:55:18 - YouTubeScraper - INFO - ‚úÖ Successfully extracted and validated data via Crawl4AI for URL: https://www.google.com/search?q=hoteles+santo+domingo&num=50&cr=countryDO&gl=DO&start=0&tbs=lr%3Alang_1en
2025-05-30 21:55:20 - YouTubeScraper - ERROR - Invalid array structure in LLM response
2025-05-30 21:55:20 - YouTubeScraper - DEBUG - Response preview: [
    {
        "index": 0,
        "error": true,
        "tags": [
            "error"
        ],
        "content": "litellm.APIError: APIError: OpenrouterException - {\"error\":{\"message\":\"This request requires more credits, or fewer max_tokens. You requested up to 8192 tokens, but can only afford 4787. To increase, visit https://openrouter.ai/settings/credits and upgrade to a paid account\",\"code\":402,\"metadata\":{\"provider_name\":null}},\"user_id\":\"user_2xg2aYeRNe8QVyGZh7KNejhcct3...
2025-05-30 21:55:20 - YouTubeScraper - INFO - ‚úÖ Extraction completed. Total results: 3
2025-05-30 21:55:20 - YouTubeScraper - INFO - üìä Success rate: 66.7% (2/3)
2025-05-30 21:55:20 - YouTubeScraper - DEBUG - Results preview: [
  {
    "metadata": {
      "context": {
        "query": "restaurantes zona colonial",
        "url": "https://www.google.com/search?q=restaurantes+zona+colonial&num=50&cr=countryDO&gl=DO&start=0&tbs=lr%3Alang_1en",
        "results": 24000
      },
      "result": {
        "success": true,
        "urls_found": 15,
        "error": null,
        "error_details": null
      }
    },
    "urls": [
      {
        "title": "Ocho restaurantes donde comer en la Zona Colonial Diario Librehttps://www.diariolibre.com \u203a revista \u203a cultura \u203a ocho\\-re...",
        "reason": "Points to a Diario Libre article listing restaurants in Zona Colonial, DR",
        "url": "https://www.diariolibre.com/revista/cultura/ocho-restaurantes-donde-comer-en-la-zona-colonial-GD27244772"
      },
      {
        "title": "Ocho restaurantes donde comer en la Zona Colonial elpaisaldia.dohttps://elpaisaldia.do \u203a Destacados",
        "reason": "Points to elpaisaldia.do article listing restauran...
2025-05-30 21:55:20 - YouTubeScraper - INFO - ‚úÖ Extraction completed successfully
2025-05-30 21:55:20 - YouTubeScraper - INFO - üìä Results: 3 search results processed
2025-05-30 21:55:20 - YouTubeScraper - INFO - üìä Total business URLs extracted: 25
2025-05-30 21:55:20 - YouTubeScraper - INFO - üíæ Saved search data: 7 raw items, 40 cleaned entities
2025-05-30 21:55:20 - YouTubeScraper - DEBUG - Final extraction results saved to debug files
2025-05-30 21:55:20 - YouTubeScraper - INFO - ‚úÖ Test completed successfully
2025-05-30 21:55:20 - YouTubeScraper - INFO - üìä Processed 3 search results
2025-05-30 21:55:20 - YouTubeScraper - INFO - üìä Extracted 25 business URLs
2025-05-30 21:55:20 - YouTubeScraper - INFO - Sample result 1: 15 URLs found
2025-05-30 21:55:20 - YouTubeScraper - INFO -   - Ocho restaurantes donde comer en la Zona Colonial Diario Librehttps://www.diariolibre.com ‚Ä∫ revista ‚Ä∫ cultura ‚Ä∫ ocho\-re...: https://www.diariolibre.com/revista/cultura/ocho-restaurantes-donde-comer-en-la-zona-colonial-GD27244772
2025-05-30 21:55:20 - YouTubeScraper - INFO -   - Ocho restaurantes donde comer en la Zona Colonial elpaisaldia.dohttps://elpaisaldia.do ‚Ä∫ Destacados: https://elpaisaldia.do/2021/07/09/ocho-restaurantes-donde-comer-en-la-zona-colonial/
2025-05-30 21:55:20 - YouTubeScraper - INFO -   - Jalao - 100% de Aqu√≠ jalao.dohttps://jalao.do: https://jalao.do/
2025-05-30 21:55:20 - YouTubeScraper - INFO - Sample result 2: 10 URLs found
2025-05-30 21:55:20 - YouTubeScraper - INFO -   - Busca hoteles en Santo Domingo Booking.com: https://www.booking.com/city/do/santo-domingo.es.html
2025-05-30 21:55:20 - YouTubeScraper - INFO -   - santo domingo este hotels - B√∫squeda de hoteles de ... - Google: https://www.google.com.do/travel/hotels/santo-domingo-este-hotels
2025-05-30 21:55:20 - YouTubeScraper - INFO -   - Hoteles en El Malec√≥n, Santo Domingo. - Booking.com: https://www.booking.com/district/do/santo-domingo/maleconarea.es.html
